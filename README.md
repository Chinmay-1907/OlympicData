# ğŸ… End-to-End Data Engineering Project: Olympic Data Analysis

Built an **end-to-end pipeline** using **Azure Data Factory** and **Databricks (Spark)** to integrate, transform, and analyze Olympic data. 
Perfomring **Extration** of data from an API, **Transforming** the data by using vairous data wrangling and cleaning methods, and lastly **Loading** the Data to a cloud database (Azure) Completing the full ETL Pipeline

---

## ğŸ“‚ Dataset
- **Source**: Olympic Data via API

---

## ğŸ›  Tools and Frameworks
- **Tools**: Azure Data Factory, Databricks (Spark)
- **Platform**: Azure Data Lake Gen 2

---

## ğŸ” Project Workflow
1. **API Integration**: Fetched Olympic data using API.
2. **ETL Processing**: Used Azure Data Factory for data extraction, transformation, and loading.
3. **Data Analysis**: Performed analysis in Databricks using Spark.

---

## ğŸ“Š Results
- **Transformed Data**: Stored in Data Lake Gen 2 for downstream analysis.
- **Insights**: Analyzed Olympic athlete performance and medal distributions.

---
